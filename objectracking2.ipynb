{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9087a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 46) (4008107202.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 46\u001b[1;36m\u001b[0m\n\u001b[1;33m    CamShift: MeanShift'in geliştirilmiş bir versiyonudur ve nesnenin boyutunu ve yönünü sürekli olarak güncelleyerek\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 46)\n"
     ]
    }
   ],
   "source": [
    "#mean shift\n",
    "Başlangıç Noktası: İlk olarak, takip etmek istediğiniz nesnenin bir başlangıç pozisyonunu (örneğin bir dikdörtgen) belirlersiniz.\n",
    "    \n",
    "    \n",
    "Yoğunluk Hesaplama: Belirli bir bölgedeki piksellerin yoğunluğunu hesaplamak için bir kernel (örneğin bir Gauss dağılımı) kullan\n",
    "ılır. Bu işlem, nesnenin rengi veya özellikleri hakkında bilgi toplamak için yapılır.\n",
    "\n",
    "Hareket: MeanShift algoritması, piksel yoğunluğunun en yüksek olduğu yöne doğru hareket eder. Bu, nesnenin yeni konumunu bulmak\n",
    "için bir \"merkez\" hesaplamayı içerir.\n",
    "Tekrar: Bu süreç, yeni merkez bulunana kadar (veya belirli bir durma koşulu sağlanana kadar) tekrarlanır.\n",
    "    \n",
    "Avantajları:\n",
    "\n",
    "Basit ve hızlıdır.\n",
    "Belirli bir renk veya özellikteki nesneleri takip etmekte etkilidir.\n",
    "Dezavantajları:\n",
    "\n",
    "Çok hızlı hareket eden nesnelerde başarısız olabilir.\n",
    "Çeşitli nesnelerin rengi benzer olduğunda karışıklığa neden olabilir.\n",
    "\n",
    "\n",
    "\n",
    "#cam shift \n",
    "Başlangıç Noktası: İlk olarak, takip etmek istediğiniz nesnenin başlangıç konumunu (bir dikdörtgen) belirleyin.\n",
    "    \n",
    "Yoğunluk Hesaplama: Aynı şekilde, nesnenin piksel yoğunluğunu belirlemek için bir histogram oluşturulur.\n",
    "    \n",
    "Adaptif Güncelleme: CamShift, her bir döngüde nesnenin boyutunu ve yönünü güncelleyebilir. Bu, nesnenin konumunu bulmanın yanı\n",
    "sıra, nesnenin boyutundaki değişiklikleri de hesaba katar.\n",
    "\n",
    "Merkez ve Boyut Belirleme: Algoritma, yoğunluk merkezini belirledikten sonra, nesnenin boyutunu da güncelleyerek daha doğru \n",
    "bir takip sağlar.\n",
    "\n",
    "Avantajları:\n",
    "\n",
    "Nesnenin boyutundaki değişiklikleri izleyebilir (büyüme veya küçülme).\n",
    "Daha iyi doğruluk ve kararlılık sağlar.\n",
    "Dezavantajları:\n",
    "\n",
    "Daha karmaşık ve işlemci açısından daha yoğun olabilir.\n",
    "Renk ve doku gibi özelliklerin sürekli güncellenmesi gerekir.\n",
    "Özet\n",
    "MeanShift: Basit, hızlı ve yoğunluk temelli bir nesne takip algoritmasıdır. Ancak, nesne boyutundaki değişiklikleri\n",
    "göz ardı eder.\n",
    "\n",
    "CamShift: MeanShift'in geliştirilmiş bir versiyonudur ve nesnenin boyutunu ve yönünü sürekli olarak güncelleyerek \n",
    "daha esnek bir takip sağlar.\n",
    "\n",
    "\n",
    "#ağırlıklı ortalama ile yakındaki noktaların çoğunu nerede olduğunu kümeleme ile belirleyip yönünü hesaplayacaz \n",
    "##sslere bak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ad5717",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prev_face_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Önceki ve şimdiki yüz koordinatlarını karşılaştırın\u001b[39;00m\n\u001b[0;32m     67\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Hareket eşiği\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(face_x \u001b[38;5;241m-\u001b[39m prev_face_x) \u001b[38;5;241m>\u001b[39m threshold \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(face_y \u001b[38;5;241m-\u001b[39m prev_face_y) \u001b[38;5;241m>\u001b[39m threshold:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Sadece yeterince büyük bir hareket olduğunda dikdörtgeni güncelleyin\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x,y), (x\u001b[38;5;241m+\u001b[39mw,y\u001b[38;5;241m+\u001b[39mh), (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Önceki yüz pozisyonunu güncelle\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prev_face_x' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Capture a video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# take first frame of the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Yüz algılama için Haarcascade dosyasını yükle\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Yüzleri algıla\n",
    "face_rects = face_cascade.detectMultiScale(frame)\n",
    "\n",
    "# Eğer yüz algılanmazsa uyarı ver\n",
    "if len(face_rects) == 0:\n",
    "    print(\"Yüz algılanamadı!\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "# Convert this list of a single array to a tuple of (x, y, w, h)\n",
    "(face_x, face_y, w, h) = tuple(face_rects[0]) \n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "# Set up the ROI for tracking\n",
    "roi = frame[face_y:face_y+h, face_x:face_x+w]\n",
    "\n",
    "# Use the HSV Color Mapping\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Find histogram to backproject the target on each frame for calculation of meanshift\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "\n",
    "# Normalize the histogram array values given a min of 0 and max of 255\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Grab the Frame in HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Calculate the Back Projection based off the roi_hist created earlier\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "        # Apply meanshift to get the new coordinates of the rectangle\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw the new rectangle on the image\n",
    "        x, y, w, h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 5)\n",
    "\n",
    "        cv2.imshow('img2', img2)\n",
    "\n",
    "        k = cv2.waitKey(100) & 0xff  Buradaki değeri artırmak yenileme hızını yavaşlatabilir.\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "# Önceki ve şimdiki yüz koordinatlarını karşılaştır\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u satır, yüzleri algılar. detectMultiScale fonksiyonu, frame içindeki yüzleri arar ve her bir yüzün pozisyonunu,\n",
    "(x, y, w, h) değerleriyle döndürür.\n",
    "\n",
    "(x, y) yüzün üst sol köşesini temsil eder.\n",
    "w ve h ise yüzün genişliği ve yüksekliğidir.\n",
    "\n",
    "\n",
    "Yüzün Koordinatları: Bu satırda, face_rects tarafından döndürülen ilk yüzün (x, y, w, h) koordinatları alınıyor.\n",
    "Bu koordinatlar, yüzün bulunduğu dikdörtgeni tanımlar.\n",
    "\n",
    "(x, y): Yüzün üst sol köşesinin koordinatlarıdır.\n",
    "w: Yüzün genişliği.\n",
    "h: Yüzün yüksekliği.\n",
    "    \n",
    "Takip Penceresi: track_window değişkeni, bu (x, y, w, h) koordinatlarını bir tuple haline getirir ve yüzü takip etmek için \n",
    "başlangıçta kullanılacak bölgeyi tanımlar. Bu pencere, yüzün başlangıçtaki konumudur.\n",
    "\n",
    "Örnek: Eğer face_rects[0] şu değerlere sahipse:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "face_rects[0] = [150, 100, 50, 70]\n",
    "Bu durumda:\n",
    "\n",
    "face_x = 150, face_y = 100 olur.\n",
    "w = 50, h = 70 olur.\n",
    "track_window = (150, 100, 50, 70) olur, yani yüz 150x100 konumunda ve 50 genişliğinde, 70 yüksekliğinde bir \n",
    "dikdörtgenle işaretlenir.\n",
    "\n",
    "\n",
    "\n",
    " Eğer yüzün track_window değeri (150, 100, 50, 70) ise, bu satır:\n",
    "\n",
    "face_y = 100 ve h = 70 olduğu için satır aralığı 100:100+70 olur.\n",
    "face_x = 150 ve w = 50 olduğu için sütun aralığı 150:150+50 olur. Bu durumda, yüzün bulunduğu bölge frame[100:170, 150:200] olarak belirlenir\n",
    "    . Bu bölgeyi kullanarak yüzün renk özellikleri incelenecek.\n",
    "    \n",
    "    \n",
    "    \n",
    "HSV Renk Uzayına Dönüştürme: cv2.cvtColor fonksiyonu, ROI'yi (yüzün bulunduğu bölgeyi) BGR renk uzayından HSV renk uzayına\n",
    "dönüştürür. HSV (Hue, Saturation, Value) renk modeli, renklerin ton, doygunluk ve parlaklık bileşenlerini temsil eder. \n",
    "Bu model, renk tabanlı takip algoritmaları için daha uygundur çünkü parlaklık değişikliklerinden daha az etkilenir.\n",
    "\n",
    "\n",
    "Hue (Ton): Rengin türü (0-179 arası değer alır).\n",
    "Saturation (Doygunluk): Rengin yoğunluğu.\n",
    "Value (Parlaklık): Rengin ışık seviyesi.\n",
    "Histogram Hesaplama: cv2.calcHist fonksiyonu, ROI'deki ton (hue) kanalının histogramını çıkarır. Histogram, \n",
    "renk dağılımlarını gösterir ve her bir renk tonunun ne kadar sık tekrarlandığını ifade eder.\n",
    "\n",
    "\n",
    "\n",
    "cv2.calcHist([hsv_roi], [0], None, [180], [0, 180]): Burada 0 kanalı yani Hue (Ton) kanalı alınır ve 0-180 arasında bir\n",
    "histogram çıkarılır.\n",
    "Histogramı Normalizasyonu: cv2.normalize fonksiyonu, histogramı 0 ile 255 arasında normalize eder. Bu işlem\n",
    ", farklı görüntü aydınlatma koşullarına rağmen daha tutarlı bir takip sağlamak için kullanılır.\n",
    "\n",
    "Örnek:\n",
    "\n",
    "Bir yüz bölgesinde, çoğunlukla ten rengi ve biraz saç rengi varsa, histogram şu şekilde olabilir:\n",
    "Hue (Ton): 0-50 arası değerlerde bir yoğunluk olabilir (ten rengi tonları).\n",
    "Saturation (Doygunluk): Yüzdeki farklı renk yoğunluklarını gösterir.\n",
    "Value (Parlaklık): Parlak bölgeleri gösterir (gözler veya yüz parlak alanları).\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Her Karede Yüz Takibi: Bu döngüde, her yeni karede yüzü takip etmek için işlemler yapılır.\n",
    "\n",
    "HSV'ye Dönüştürme: Her kare (frame), yüzün renk özelliklerini daha kolay izleyebilmek için HSV renk uzayına dönüştürülür.\n",
    "\n",
    "Back Projection (Geri Projeksiyon): cv2.calcBackProject fonksiyonu, önceki adımda elde edilen ROI histogramını kullanarak,\n",
    "her karede yüzün olabileceği bölgeleri tahmin eder. Bu tahminler, görüntüdeki her bir pikselin histogramla ne kadar eşleştiğini \n",
    "gösterir.\n",
    "\n",
    "\n",
    "\n",
    "Geri Projeksiyon Nedir? Histogram ile her pikselin uyumluluğunu hesaplayarak, hedef nesnenin (yüz) olabileceği bölgeleri geri\n",
    "projekte eder. Yani, histogram bilgisi kullanılarak yüzün yeni konumu belirlenir.\n",
    "\n",
    "\n",
    "MeanShift Algoritması: cv2.meanShift fonksiyonu, yüzün yeni konumunu bulmak için MeanShift algoritmasını kullanır.\n",
    "    MeanShift, geri projeksiyon sonuçlarına göre yüzün hareket ettiği yeni bölgeyi bulur ve takip penceresini (track_window) \n",
    "günceller. Yani, yüz hareket ettikçe yeni (x, y, w, h) koordinatları bulunur.\n",
    "\n",
    "\n",
    "Örnek:\n",
    "\n",
    "Örneğin, yüz başlangıçta (150, 100, 50, 70) konumundaysa ve geri projeksiyon sonucu yüzün yeni konumu (160, 110, 50, 70) olarak hesaplandıysa, track_window bu yeni konuma taşınacaktır.\n",
    "MeanShift Algoritması Hakkında:\n",
    "\n",
    "MeanShift algoritması, bir hedef nesnenin (bu durumda yüz) hareketini takip etmek için yoğunluk bazlı bir algoritmadır. Piksel değerlerinin yoğunluğunu dikkate alarak yüzün olabileceği en yoğun bölgeye hareket eder. Bu sayede, yüzün hangi yöne hareket ettiğini belirlemek mümkündür.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
